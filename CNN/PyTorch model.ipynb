{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Classification \n",
    "\n",
    "This notebook is a basic example for training and testing CNN model with PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the PyTorch model and runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, kernel_size=3, batchnorm=True, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.c1 = nn.Conv2d(in_filters, out_filters, kernel_size, padding=padding)\n",
    "        self.bn = batchnorm\n",
    "        self.b1 = nn.BatchNorm2d(out_filters)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        if self.bn: \n",
    "            x = self.b1(x)\n",
    "        return x\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__ (self, imgsize=32, num_classes=10, in_filters=1, filters=8, kernel_size=3, batchnorm=True, activ=F.relu, padding=1):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.activ = activ\n",
    "        self.bn = batchnorm\n",
    "        self.imgsize = imgsize\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.activ = activ\n",
    "        self.conv1 = ConvBlock(in_filters=in_filters, out_filters=filters, \n",
    "                               kernel_size=kernel_size, batchnorm=batchnorm, padding=padding)\n",
    "        self.conv2 = ConvBlock(in_filters=filters, out_filters=filters, \n",
    "                               kernel_size=kernel_size, batchnorm=batchnorm, padding=padding)\n",
    "        \n",
    "        self.fc1 = nn.Linear(filters * imgsize ** 2, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activ(self.conv1(x))\n",
    "        x = self.activ(self.conv2(x))\n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.activ(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__ (self, imgsize=32, num_classes=10, in_filters=1, filters=8, kernel_size=3, batchnorm=True, activ=F.relu):\n",
    "        \"\"\"\n",
    "        Trainer for the CNN\n",
    "\n",
    "        @num_epochs: Number of epochs\n",
    "        @lr: initial learning rate\n",
    "        @batch_size: Size of single batch\n",
    "        @decay: decay LR by 3 after these many epochs\n",
    "        \"\"\"\n",
    "        self.imgsize = imgsize\n",
    "        self.net = Net(imgsize=imgsize, num_classes=num_classes, in_filters=in_filters, filters=filters, kernel_size=kernel_size,\n",
    "                       batchnorm=batchnorm, activ=activ)\n",
    "        \n",
    "        self.cuda_flag = torch.cuda.is_available()\n",
    "        if self.cuda_flag:\n",
    "            self.net = self.net.cuda()\n",
    "\n",
    "    def train(self, X, Y, epochs=10, lr=0.001, batch_size=64, decay=5000, logging=True, log_file=None):\n",
    "        \"\"\"\n",
    "        Train the CNN\n",
    "\n",
    "        Params:\n",
    "        @X: Training data - input of the model\n",
    "        @Y: Training labels\n",
    "        @logging: True for printing the training progress after each epoch\n",
    "        @log_file: Path of log file\n",
    "        \"\"\"\n",
    "        X = [x.reshape(1, self.imgsize, self.imgsize) for x in X]\n",
    "        \n",
    "        inputs = torch.FloatTensor(X)\n",
    "        labels = torch.LongTensor(Y)\n",
    "        \n",
    "        train_dataset = TensorDataset(inputs, labels)\n",
    "        trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        self.net.train()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(1, epochs+1): # loop over data multiple times\n",
    "            # Decreasing the learning rate\n",
    "            if (epoch % decay == 0):\n",
    "                lr /= 3\n",
    "                \n",
    "            optimizer = optim.SGD(self.net.parameters(), lr=lr, momentum=0.9)\n",
    "            \n",
    "            tot_loss = 0.0\n",
    "            for data in tqdm(trainloader):\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                if self.cuda_flag:\n",
    "                    inputs = inputs.cuda()\n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                o = self.net(inputs)\n",
    "                loss = criterion(o, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                tot_loss += loss.item()\n",
    "                \n",
    "            tot_loss /= len(trainloader)\n",
    "\n",
    "            # logging statistics\n",
    "            timestamp = str(datetime.datetime.now()).split('.')[0]\n",
    "            log = json.dumps({\n",
    "                'timestamp': timestamp,\n",
    "                'epoch': epoch,\n",
    "                'loss': float('%.7f' % tot_loss),\n",
    "                'lr': float('%.6f' % lr)\n",
    "            })\n",
    "            if logging:\n",
    "                print (log)\n",
    "\n",
    "            if log_file is not None:\n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(\"{}\\n\".format(log))\n",
    "            \n",
    "        print ('Finished Training')\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "        Predict the task labels corresponding to the input images\n",
    "        \"\"\"\n",
    "        inputs = [x.reshape(1, self.imgsize, self.imgsize) for x in inputs]\n",
    "        inputs = torch.FloatTensor(inputs)\n",
    "        if self.cuda_flag:\n",
    "            inputs = inputs.cuda()\n",
    "\n",
    "        self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            labels = self.net(inputs).cpu().numpy()\n",
    "            \n",
    "        return np.argmax(labels, axis=1)\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        \"\"\"\n",
    "        Score the model -- compute accuracy\n",
    "        \"\"\"\n",
    "        pred = self.predict(X)\n",
    "        acc = np.sum(pred == Y) / len(Y)\n",
    "        return float(acc)\n",
    "\n",
    "    def save_model(self, checkpoint_path, model=None):\n",
    "        if model is None: model = self.net\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    def load_model(self, checkpoint_path, model=None):\n",
    "        if model is None: model = self.net\n",
    "        if self.cuda_flag:\n",
    "            model.load_state_dict(torch.load(checkpoint_path))\n",
    "        else:\n",
    "            model.load_state_dict(torch.load(checkpoint_path, map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: root_numpy in /mnt/e/arpanmangal/anaconda3/envs/tmva/lib/python3.7/site-packages (4.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Welcome to JupyROOT 6.21/01\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from subprocess import call\n",
    "\n",
    "%pip install root_numpy\n",
    "from root_numpy import root2array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data_file, test_split=0.2):\n",
    "    \"\"\"\n",
    "    @data_file: path of the root file\n",
    "    @test_split: fraction of data to be used as test set\n",
    "    \"\"\"\n",
    "    assert 0 <= test_split <= 0.3\n",
    "\n",
    "    # Load data\n",
    "    signal = root2array(data_file, 'sig_tree')\n",
    "    background = root2array(data_file, 'bkg_tree')\n",
    "\n",
    "    tree_data = [\n",
    "        np.array([img[0] for img in signal]),\n",
    "        np.array([img[0] for img in background])\n",
    "    ]\n",
    "\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "\n",
    "    # Deterministic Random\n",
    "    np.random.seed(0)\n",
    "\n",
    "    for label, data in enumerate(tree_data):\n",
    "        np.random.shuffle(data)\n",
    "\n",
    "        test_size = int(len(data) * test_split)\n",
    "        X_train.append(data[:-test_size])\n",
    "        X_test.append(data[-test_size:])\n",
    "        Y_train.append([label] * (len(data) - test_size))\n",
    "        Y_test.append([label] * test_size)\n",
    "\n",
    "    X_train = np.concatenate(X_train, axis=0)\n",
    "    X_test = np.concatenate(X_test, axis=0)\n",
    "    Y_train = np.concatenate(Y_train)\n",
    "    Y_test = np.concatenate(Y_test)\n",
    "\n",
    "    assert len(Y_train) == len(X_train)\n",
    "    assert len(Y_test) == len(X_test)\n",
    "\n",
    "    # Shuffling the data\n",
    "    train_perm = np.random.permutation(len(X_train))\n",
    "    X_train = X_train[train_perm]\n",
    "    Y_train = Y_train[train_perm]\n",
    "    \n",
    "    test_perm = np.random.permutation(len(X_test))\n",
    "    X_test = X_test[test_perm]\n",
    "    Y_test = Y_test[test_perm]\n",
    "    \n",
    "    return (X_train, Y_train), (X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "inputFile = 'sample_images_32x32.root'\n",
    "if not os.path.isfile(inputFile):\n",
    "    call(['curl', '-o', inputFile, 'https://cernbox.cern.ch/index.php/s/mba2sFJ3ugoy269/download'])\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = get_dataset(inputFile, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model config\n",
    "lr = 0.0003\n",
    "num_epochs = 20\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e80d6b8698241a3a045d41c67bd870f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:06:09\", \"epoch\": 1, \"loss\": 0.671591, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31589f3a1e174fc38e142dfd088be21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:06:13\", \"epoch\": 2, \"loss\": 0.591326, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd42d52e420485e91db5d8d68310763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:06:17\", \"epoch\": 3, \"loss\": 0.4519308, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7f88f008fb44f19a748f9f7f05eab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:06:21\", \"epoch\": 4, \"loss\": 0.2858451, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba3ca2575e747e2b5ff3a3fd66da8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:06:25\", \"epoch\": 5, \"loss\": 0.1693994, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df81f0646a2489cbdd276e16c6579f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:06:29\", \"epoch\": 6, \"loss\": 0.1049665, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6975c2b26ea945da9b6b65da6a75e6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:06:33\", \"epoch\": 7, \"loss\": 0.0713114, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3cbdcf27fc3408cb48b4725bf3ebaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:06:37\", \"epoch\": 8, \"loss\": 0.0523345, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9a6aeac38045e09bdea660f95e1576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:06:41\", \"epoch\": 9, \"loss\": 0.0419883, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceda6df82419497fbf5026ad5da8c38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:06:45\", \"epoch\": 10, \"loss\": 0.0343118, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fae21fbfcf4aa9b9302d93ae358e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:06:48\", \"epoch\": 11, \"loss\": 0.0289593, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b074230da940fca3c8e255d0937bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:06:52\", \"epoch\": 12, \"loss\": 0.0241951, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d161d0f525a14d91afa0e377006e7567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:06:56\", \"epoch\": 13, \"loss\": 0.0213591, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f262f7b61cb4ced8f6af1533c8b5cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:07:00\", \"epoch\": 14, \"loss\": 0.0186974, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db3be0e9f8b4c978f5d5ba99022b13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:07:04\", \"epoch\": 15, \"loss\": 0.0169093, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd942890e9de45d997b9b12d4187398c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:07:08\", \"epoch\": 16, \"loss\": 0.015077, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc8260ed88442e8b6618317800e7ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:07:11\", \"epoch\": 17, \"loss\": 0.0140529, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c8fc315e284f09990774111f6dc4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:07:15\", \"epoch\": 18, \"loss\": 0.0125363, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c82338876a9423586ebb2bc6b9f2829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:07:19\", \"epoch\": 19, \"loss\": 0.0119496, \"lr\": 0.0003}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b822c73f357749bd9d3d325f6a468c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"timestamp\": \"2020-03-17 15:07:23\", \"epoch\": 20, \"loss\": 0.0114691, \"lr\": 0.0003}\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(imgsize=32, num_classes=2)\n",
    "trainer.train(X_train, Y_train, lr=lr, epochs=num_epochs, batch_size=batch_size)\n",
    "trainer.save_model('model_cnn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Training Acc.: 99.9875 %\n",
      "Test Acc.    : 99.9750 %\n"
     ]
    }
   ],
   "source": [
    "print ('Evaluating...')\n",
    "print ('Training Acc.: {:.4f} %'.format(trainer.score(X_train, Y_train) * 100))\n",
    "print ('Test Acc.    : {:.4f} %'.format(trainer.score(X_test, Y_test) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
