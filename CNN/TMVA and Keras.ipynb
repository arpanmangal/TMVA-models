{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMVA Classification \n",
    "\n",
    "This notebook is a basic example for training and testing CNN model with TMVA and TMVA-Keras.\n",
    "\n",
    "(Based on TMVA Tutorials: https://github.com/lmoneta/tmva-tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Factory class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.21/01\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "from ROOT import TMVA\n",
    "from subprocess import call\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT.TMVA.Tools.Instance()\n",
    "TMVA.PyMethodBase.PyInitialize()\n",
    "\n",
    "## For PYMVA methods\n",
    "TMVA.PyMethodBase.PyInitialize();\n",
    "\n",
    "\n",
    "outputFile = ROOT.TFile.Open(\"CNN_ClassificationOutput.root\", \"RECREATE\")\n",
    "\n",
    "factory = ROOT.TMVA.Factory(\"TMVA_CNN_Classification\", outputFile,\n",
    "                      \"!V:ROC:Silent:Color:!DrawProgressBar:AnalysisType=Classification\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare DataLoader(s)\n",
    "\n",
    "Next we get the data and declare the DataLoader class.\n",
    "\n",
    "In this case the input data consists of an image of 32x32 pixels. Each ROOT TTree contains a single branch containg a vector of size 1024 denoting the image pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "inputFileName = \"sample_images_32x32.root\"\n",
    "\n",
    "if not os.path.isfile(inputFileName):\n",
    "    call(['curl', '-o', inputFileName, 'https://cernbox.cern.ch/index.php/s/mba2sFJ3ugoy269/download'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************\n",
      "*Tree    :sig_tree  : signal_tree                                            *\n",
      "*Entries :    10000 : Total =        41219997 bytes  File  Size =   37110195 *\n",
      "*        :          : Tree compression factor =   1.11                       *\n",
      "******************************************************************************\n",
      "*Br    0 :vars      : vector<float>                                          *\n",
      "*Entries :    10000 : Total  Size=   41219579 bytes  File Size  =   37100381 *\n",
      "*Baskets :     1158 : Basket Size=    3265024 bytes  Compression=   1.11     *\n",
      "*............................................................................*\n"
     ]
    }
   ],
   "source": [
    "inputFile = ROOT.TFile.Open( inputFileName )\n",
    "\n",
    "# retrieve input trees\n",
    "signalTree     = inputFile.Get(\"sig_tree\")\n",
    "backgroundTree = inputFile.Get(\"bkg_tree\")\n",
    "\n",
    "signalTree.Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create data set info dataset\n"
     ]
    }
   ],
   "source": [
    "dataloader = TMVA.DataLoader('dataset')\n",
    "\n",
    "### Adding the trees\n",
    "dataloader.AddSignalTree(signalTree, 1.0)\n",
    "dataloader.AddBackgroundTree(backgroundTree, 1.0)\n",
    "\n",
    "# Add variables\n",
    "imgsize = 32 * 32\n",
    "for i in range(imgsize):\n",
    "    varName = \"var_{} := vars[{}]\".format(i,i)\n",
    "    dataloader.AddVariable(varName,'F')\n",
    "\n",
    "dataloader.PrepareTrainingAndTestTree( ROOT.TCut(''), ROOT.TCut(''),\n",
    "                                  \"nTrain_Signal=8000:nTrain_Background=8000:SplitMode=Random:\"\n",
    "                                   \"NormMode=NumEvents:!V\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Booking Methods\n",
    "\n",
    "Here we book the TMVA and TMVA-Keras methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Convolutional Neural Network in TMVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cppyy.gbl.TMVA.MethodDL object at 0x7fffc48647f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input layout \n",
    "inputLayoutString = \"InputLayout=1|32|32\"\n",
    "                                                                           \n",
    "## Batch Layout                                                                                                                                     \n",
    "batchLayoutString = \"BatchLayout=64|1|1024\"\n",
    "                                                   \n",
    "layoutString = (\"Layout=CONV|8|3|3|1|1|1|1|RELU,BNORM,CONV|8|3|3|1|1|1|1|RELU,\"\n",
    "                \"BNORM,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|TANH\")\n",
    "\n",
    "##Training strategies.                                                                                                                          \n",
    "training1 = (\"LearningRate=0.0003,Momentum=0.9,Repetitions=1,\"\n",
    "                     \"ConvergenceSteps=10,BatchSize=64,TestRepetitions=1,\"\n",
    "                     \"MaxEpochs=20,WeightDecay=1e-4,Regularization=None,\"\n",
    "                     \"Optimizer=SGD,DropConfig=0.0+0.0+0.0+0.0\")\n",
    " \n",
    "trainingStrategyString = \"TrainingStrategy=\" + training1\n",
    "    \n",
    "## General Options.                                                                                                                              \n",
    "cnnOptions = (\"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\"\n",
    "                       \"WeightInitialization=XAVIERUNIFORM\")\n",
    "\n",
    "cnnOptions +=  \":\" + inputLayoutString\n",
    "cnnOptions +=  \":\" + batchLayoutString\n",
    "cnnOptions +=  \":\" + layoutString\n",
    "cnnOptions +=  \":\" + trainingStrategyString\n",
    "cnnOptions +=  \":Architecture=CPU\"\n",
    "\n",
    "##book CNN\n",
    "factory.BookMethod(dataloader, TMVA.Types.kDL, \"DL_CNN\", cnnOptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Convolutional Neural Network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to use tensorflow backend\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 8)         80        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 8)         32        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 8)         584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 8)         32        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                524352    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 525,210\n",
      "Trainable params: 525,178\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-17 21:41:48.283480: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-03-17 21:41:48.293204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2208000000 Hz\n",
      "2020-03-17 21:41:48.295060: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fffc4711680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-17 21:41:48.295165: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-03-17 21:41:48.295592: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Generate model\n",
    "batch_size = 64\n",
    "num_classes = 2\n",
    "epochs = 20\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Reshape((32, 32, 1), input_shape=(imgsize,)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Set loss and optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.0003, decay=1e-6, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Store model to file\n",
    "model.save('model_cnn.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cppyy.gbl.TMVA.MethodPyKeras object at 0x7fad1871fd30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-17 21:41:48.439258: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Book method\n",
    "factory.BookMethod(dataloader, TMVA.Types.kPyKeras, 'PyKeras',\n",
    "                   'H:!V:VarTransform=None:FilenameModel=model_cnn.h5:'\n",
    "                   'FileNameTrainedModel=trained_model_cnn.h5:NumEpochs={}:BatchSize={}'.format(epochs, batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 8)         80        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 8)         32        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 8)         584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 8)         32        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                524352    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 525,210\n",
      "Trainable params: 525,178\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/20\n",
      "12800/12800 [==============================] - 27s 2ms/step - loss: 0.6680 - accuracy: 0.6133 - val_loss: 0.6149 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61490, saving model to trained_model_cnn.h5\n",
      "Epoch 2/20\n",
      "12800/12800 [==============================] - 27s 2ms/step - loss: 0.4435 - accuracy: 0.8313 - val_loss: 0.3305 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61490 to 0.33049, saving model to trained_model_cnn.h5\n",
      "Epoch 3/20\n",
      "12800/12800 [==============================] - 28s 2ms/step - loss: 0.2471 - accuracy: 0.9480 - val_loss: 0.1759 - val_accuracy: 0.9787\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33049 to 0.17586, saving model to trained_model_cnn.h5\n",
      "Epoch 4/20\n",
      "12800/12800 [==============================] - 27s 2ms/step - loss: 0.1467 - accuracy: 0.9748 - val_loss: 0.1057 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17586 to 0.10573, saving model to trained_model_cnn.h5\n",
      "Epoch 5/20\n",
      "12800/12800 [==============================] - 26s 2ms/step - loss: 0.0861 - accuracy: 0.9926 - val_loss: 0.0770 - val_accuracy: 0.9925\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.10573 to 0.07695, saving model to trained_model_cnn.h5\n",
      "Epoch 6/20\n",
      "12800/12800 [==============================] - 25s 2ms/step - loss: 0.0603 - accuracy: 0.9955 - val_loss: 0.0547 - val_accuracy: 0.9969\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07695 to 0.05474, saving model to trained_model_cnn.h5\n",
      "Epoch 7/20\n",
      "12800/12800 [==============================] - 27s 2ms/step - loss: 0.0453 - accuracy: 0.9978 - val_loss: 0.0484 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.05474 to 0.04844, saving model to trained_model_cnn.h5\n",
      "Epoch 8/20\n",
      "12800/12800 [==============================] - 26s 2ms/step - loss: 0.0374 - accuracy: 0.9983 - val_loss: 0.0384 - val_accuracy: 0.9969\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04844 to 0.03836, saving model to trained_model_cnn.h5\n",
      "Epoch 9/20\n",
      "12800/12800 [==============================] - 27s 2ms/step - loss: 0.0291 - accuracy: 0.9992 - val_loss: 0.0346 - val_accuracy: 0.9972\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03836 to 0.03462, saving model to trained_model_cnn.h5\n",
      "Epoch 10/20\n",
      "12800/12800 [==============================] - 27s 2ms/step - loss: 0.0250 - accuracy: 0.9991 - val_loss: 0.0281 - val_accuracy: 0.9975\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03462 to 0.02807, saving model to trained_model_cnn.h5\n",
      "Epoch 11/20\n",
      "12800/12800 [==============================] - 26s 2ms/step - loss: 0.0210 - accuracy: 0.9995 - val_loss: 0.0260 - val_accuracy: 0.9969\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02807 to 0.02598, saving model to trained_model_cnn.h5\n",
      "Epoch 12/20\n",
      "12800/12800 [==============================] - 27s 2ms/step - loss: 0.0183 - accuracy: 0.9995 - val_loss: 0.0222 - val_accuracy: 0.9978\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02598 to 0.02224, saving model to trained_model_cnn.h5\n",
      "Epoch 13/20\n",
      "12800/12800 [==============================] - 27s 2ms/step - loss: 0.0167 - accuracy: 0.9996 - val_loss: 0.0227 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02224\n",
      "Epoch 14/20\n",
      "12800/12800 [==============================] - 27s 2ms/step - loss: 0.0151 - accuracy: 0.9996 - val_loss: 0.0216 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02224 to 0.02162, saving model to trained_model_cnn.h5\n",
      "Epoch 15/20\n",
      "12800/12800 [==============================] - 27s 2ms/step - loss: 0.0133 - accuracy: 0.9997 - val_loss: 0.0182 - val_accuracy: 0.9987\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02162 to 0.01820, saving model to trained_model_cnn.h5\n",
      "Epoch 16/20\n",
      "12800/12800 [==============================] - 27s 2ms/step - loss: 0.0120 - accuracy: 0.9998 - val_loss: 0.0174 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01820 to 0.01741, saving model to trained_model_cnn.h5\n",
      "Epoch 17/20\n",
      "12800/12800 [==============================] - 25s 2ms/step - loss: 0.0117 - accuracy: 0.9996 - val_loss: 0.0164 - val_accuracy: 0.9975\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01741 to 0.01638, saving model to trained_model_cnn.h5\n",
      "Epoch 18/20\n",
      "12800/12800 [==============================] - 26s 2ms/step - loss: 0.0102 - accuracy: 0.9998 - val_loss: 0.0159 - val_accuracy: 0.9978\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01638 to 0.01589, saving model to trained_model_cnn.h5\n",
      "Epoch 19/20\n",
      "12800/12800 [==============================] - 26s 2ms/step - loss: 0.0096 - accuracy: 0.9998 - val_loss: 0.0145 - val_accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01589 to 0.01455, saving model to trained_model_cnn.h5\n",
      "Epoch 20/20\n",
      "12800/12800 [==============================] - 25s 2ms/step - loss: 0.0089 - accuracy: 0.9999 - val_loss: 0.0136 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01455 to 0.01363, saving model to trained_model_cnn.h5\n",
      "addBNormLayer 8 , 32 , 32 , 8  1024  64\n",
      "addBNormLayer 8 , 32 , 32 , 8  1024  1\n",
      "addBNormLayer 8 , 32 , 32 , 8  1024  64\n",
      "addBNormLayer 8 , 32 , 32 , 8  1024  1\n",
      "DEEP NEURAL NETWORK:   Depth = 7  Input = ( 1, 32, 32 )  Batch size = 64  Loss function = C\n",
      "\tLayer 0\t CONV LAYER: \t( W = 32 ,  H = 32 ,  D = 8 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 64 , 8 , 8 , 1024 ) \t Activation Function = Relu\n",
      "\tLayer 1\t BATCH NORM Layer: \t Input/Output = ( 8 , 1024 , 64 ) \t Norm dim =     8\t axis = 1\n",
      "\n",
      "\tLayer 2\t CONV LAYER: \t( W = 32 ,  H = 32 ,  D = 8 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 64 , 8 , 8 , 1024 ) \t Activation Function = Relu\n",
      "\tLayer 3\t BATCH NORM Layer: \t Input/Output = ( 8 , 1024 , 64 ) \t Norm dim =     8\t axis = 1\n",
      "\n",
      "\tLayer 4\t RESHAPE Layer \t Input = ( 8 , 32 , 32 ) \tOutput = ( 1 , 64 , 8192 ) \n",
      "\tLayer 5\t DENSE Layer: \t ( Input =  8192 , Width =    64 ) \tOutput = (  1 ,    64 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 6\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,    64 ,     1 ) \t Activation Function = Tanh\n",
      "addBNormLayer 8 , 32 , 32 , 8  1024  64\n",
      "addBNormLayer 8 , 32 , 32 , 8  1024  64\n",
      "TH1.Print Name  = TrainingHistory_DL_CNN_trainingError, Entries= 0, Total sum= 9.04023\n",
      "TH1.Print Name  = TrainingHistory_DL_CNN_valError, Entries= 0, Total sum= 8.98607\n",
      "TH1.Print Name  = TrainingHistory_PyKeras_'accuracy', Entries= 0, Total sum= 19.3468\n",
      "TH1.Print Name  = TrainingHistory_PyKeras_'loss', Entries= 0, Total sum= 1.9254\n",
      "TH1.Print Name  = TrainingHistory_PyKeras_'val_accuracy', Entries= 0, Total sum= 19.505\n",
      "TH1.Print Name  = TrainingHistory_PyKeras_'val_loss', Entries= 0, Total sum= 1.69679\n",
      "addBNormLayer 8 , 32 , 32 , 8  1024  1\n",
      "addBNormLayer 8 , 32 , 32 , 8  1024  1\n"
     ]
    }
   ],
   "source": [
    "factory.TrainAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Evaluate Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addBNormLayer 8 , 32 , 32 , 8  1024  100\n",
      "addBNormLayer 8 , 32 , 32 , 8  1024  100\n"
     ]
    }
   ],
   "source": [
    "factory.TestAllMethods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addBNormLayer 8 , 32 , 32 , 8  1024  100\n",
      "addBNormLayer 8 , 32 , 32 , 8  1024  100\n",
      "                         : \n",
      "                         : Evaluation results ranked by best signal efficiency and purity (area)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet       MVA                       \n",
      "                         : Name:         Method:          ROC-integ\n",
      "                         : dataset       PyKeras        : 1.000\n",
      "                         : dataset       DL_CNN         : 1.000\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Testing efficiency compared to training efficiency (overtraining check)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) \n",
      "                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   \n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : dataset              PyKeras        : 1.000 (1.000)       1.000 (1.000)      1.000 (1.000)\n",
      "                         : dataset              DL_CNN         : 1.000 (1.000)       1.000 (1.000)      1.000 (1.000)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "factory.EvaluateAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curve\n",
    "\n",
    "We plot here the produce ROC curve obtained on evaluating the methods on the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //We enable JavaScript visualisation for the plots\n",
    "# %jsroot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c1 = factory.GetROCCurve(dataloader);\n",
    "c1.Draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Close outputfile to save all output information (evaluation result of methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFile.Close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
